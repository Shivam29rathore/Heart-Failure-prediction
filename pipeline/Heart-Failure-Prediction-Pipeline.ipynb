{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end Heart Failure Prediction Pipeline\n",
    "\n",
    "#### Building our lightweight pipelines components using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightweight python components\n",
    "\n",
    "Lightweight python components do not require you to build a new container image for every code change. They're intended to use for fast iteration in notebook environment.\n",
    "\n",
    "#### Building a lightweight python component\n",
    "\n",
    "To build a component just define a stand-alone python function and then call kfp.components.func_to_container_op(func) to convert it to a component that can be used in a pipeline.\n",
    "\n",
    "There are several requirements for the function:\n",
    "\n",
    "- The function should be stand-alone. It should not use any code declared outside of the function definition. Any imports should be added inside the main function. Any helper functions should also be defined inside the main function.\n",
    "\n",
    "\n",
    "- The function can only import packages that are available in the base image. If you need to import a package that's not available you can try to find a container image that already includes the required packages. (As a workaround you can use the module subprocess to run pip install for the required package.)\n",
    "\n",
    "\n",
    "- If the function operates on numbers, the parameters need to have type hints. Supported types are [int, float, bool]. Everything else is passed as string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Python function-based components\n",
    "\n",
    "A Kubeflow Pipelines component is a self-contained set of code that performs one step in your ML workflow. A pipeline component is composed of:\n",
    "\n",
    "- The component code, which implements the logic needed to perform a step in your ML workflow.\n",
    "\n",
    "- A component specification, which defines the following:\n",
    "    - The component's metadata, its name and description.\n",
    "    - The component's interface, the component's inputs and outputs.\n",
    "    - The component's implementation, the Docker container image to run, how to pass inputs to your component code, and how to get the component's outputs.\n",
    "    \n",
    "\n",
    "Python function-based components make it easier to iterate quickly by letting you build your component code as a Python function and generating the component specification for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/jovyan/.local/lib/python3.6/site-packages (20.2.4)\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U --user numpy==1.19.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jovyan/.local/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/jovyan/.local/lib/python3.6/site-packages (from pandas) (1.16.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.13.0)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: pandas==0.23.4 in /home/jovyan/.local/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: matplotlib==3.3.1 in /home/jovyan/.local/lib/python3.6/site-packages (3.3.1)\n",
      "Requirement already satisfied: scipy==1.2.1 in /home/jovyan/.local/lib/python3.6/site-packages (1.2.1)\n",
      "Requirement already satisfied: scikit-learn==0.22 in /home/jovyan/.local/lib/python3.6/site-packages (0.22)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: keras==1.2.2 in /home/jovyan/.local/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: seaborn==0.10.1 in /home/jovyan/.local/lib/python3.6/site-packages (0.10.1)\n",
      "Requirement already satisfied: facets-overview==1.0.0 in /home/jovyan/.local/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/jovyan/.local/lib/python3.6/site-packages (from pandas==0.23.4) (1.16.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/jovyan/.local/lib/python3.6/site-packages (from matplotlib==3.3.1) (2020.11.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jovyan/.local/lib/python3.6/site-packages (from matplotlib==3.3.1) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.1) (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jovyan/.local/lib/python3.6/site-packages (from scikit-learn==0.22) (0.17.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.13.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.26.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorflow==2.1.0) (2.1.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow==2.1.0) (0.30.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (5.3)\n",
      "Requirement already satisfied: theano in /home/jovyan/.local/lib/python3.6/site-packages (from keras==1.2.2) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.1) (44.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[31mERROR: Double requirement given: IPython==7.11.1 (already in IPython==7.12.0, name='IPython')\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython \n",
    "!python -m pip install pandas \n",
    "!pip install pandas==0.23.4 matplotlib==3.3.1 scipy==1.2.1 scikit-learn==0.22 tensorflow==2.1.0 keras==1.2.2 seaborn==0.10.1 facets-overview==1.0.0 --user\n",
    "!pip install IPython==7.12.0 numpy==1.16.1 imblearn==0.0 jsonlib==1.6.1 tensorboard==2.2.0 DateTime==4.1.1 IPython==7.11.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install or update the pipelines SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following command to install the Kubeflow Pipelines SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already up-to-date: kfp in /home/jovyan/.local/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: kfp-pipeline-spec<0.2.0,>=0.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=0.2.5 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied, skipping upgrade: docstring-parser>=0.7.3 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from requests-toolbelt>=0.8.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /home/jovyan/.local/lib/python3.6/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=0.8.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=0.8.0->kfp) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (8.0.2)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: kfp in /home/jovyan/.local/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=0.2.5 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: docstring-parser>=0.7.3 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: kfp-pipeline-spec<0.2.0,>=0.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /home/jovyan/.local/lib/python3.6/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (8.0.2)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already up-to-date: kfp in /home/jovyan/.local/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: kfp-pipeline-spec<0.2.0,>=0.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=0.2.5 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: docstring-parser>=0.7.3 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /home/jovyan/.local/lib/python3.6/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.22.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (8.0.2)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: kfp in /home/jovyan/.local/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=0.2.5 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: docstring-parser>=0.7.3 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: kfp-pipeline-spec<0.2.0,>=0.1.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /home/jovyan/.local/lib/python3.6/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (0.6.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp) (0.4.8)\r\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.11.2)\r\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\r\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (8.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "# You may need to restart your notebook kernel after updating the kfp sdk\n",
    "!pip3 install --user --upgrade kfp\n",
    "!pip3 install kfp --upgrade\n",
    "!pip3 install kfp --upgrade --user\n",
    "!pip3 install -U kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Restart the kernel before you proceed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after the pip install\n",
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Check if the install was successful:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Components\n",
    "\n",
    "#### Import the kfp and kfp.components packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp                  # the Pipelines SDK. \n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "import kfp.components as comp\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "from kfp.dsl.types import Integer, GCSPath, String\n",
    "import kfp.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the outputs are stored\n",
    "out_dir = \"/home/jovyan/stage-f-07-heart-failure/data/out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a release experiment in the Kubeflow pipeline\n",
    "\n",
    "#### Kubeflow Pipeline requires having an Experiment before making a run. An experiment is a group of comparable runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Heart Failure Prediction Pipeline'        # Name of the experiment in the UI\n",
    "BASE_IMAGE = \"tensorflow/tensorflow:latest-gpu-py3\"    # Base image used for components in the pipeline\n",
    "\n",
    "PROJECT_NAME = \"Kubeflow-mlops-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of the kfp.Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/b9903817-ff24-4b2b-a0ff-75ee349257e1\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "exp = client.create_experiment(name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Python function-based components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your component's code as a standalone python function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_path): \n",
    "    \n",
    "     # func_to_container_op requires packages to be imported inside of the function.\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pandas import Series, DataFrame,read_csv\n",
    "    import pickle\n",
    "    \n",
    "    # Read the dataset as a csv file \n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/HamoyeHQ/stage-f-07-heart-failure/master/data/heart_failure_clinical_records_dataset.csv\")\n",
    "    \n",
    "    \n",
    "    # Re-assign the features with binary numbers to a boolean label\n",
    "    df['anaemia'] = np.where(df['anaemia'] == 1 ,True,False)\n",
    "    df['diabetes'] = np.where(df['diabetes'] == 1, True, False)\n",
    "    df['high_blood_pressure'] = np.where(df['high_blood_pressure'] == 1, True, False)\n",
    "    df['smoking'] = np.where(df['smoking'] == 1, True, False)\n",
    "    df['sex'] = np.where(df['sex'] == 1, 'Male','Female')\n",
    "    \n",
    "    \n",
    "    # prints the number of missing values in the different variables.\n",
    "    df.apply(lambda x: sum(x.isnull()),axis=0)\n",
    "    \n",
    "    #Delete row with dummy value\n",
    "    df = df.dropna(how='any',axis=0)\n",
    "    \n",
    "    # Save Dataframe using the pickle extension\n",
    "    df.to_pickle(f'{data_path}/preprocessed-data.pkl')\n",
    "    print(\"Preprocessing Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "def Analyze(data_path):\n",
    "    \n",
    "     # func_to_container_op requires packages to be imported inside of the function. \n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'matplotlib==3.3.1']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'seaborn==0.10.1']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'facets-overview==1.0.0'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'IPython==7.12.0'])\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from pandas import Series\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Read the dataset as a csv file\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/HamoyeHQ/stage-f-07-heart-failure/master/data/heart_failure_clinical_records_dataset.csv\")\n",
    "    \n",
    "    # Statistical Inference from data\n",
    "    df.describe()\n",
    "    \n",
    "    # Split into Features and Labels\n",
    "    x = df.drop('DEATH_EVENT', axis = 1)\n",
    "    y = df['DEATH_EVENT']\n",
    "    \n",
    "#     @title Install the facets_overview pip package.\n",
    "#     import facets-overview\n",
    "    \n",
    "    train_data = x[0:150] \n",
    "    test_data = x[150: ]\n",
    "    \n",
    "    \n",
    "    # Create the feature stats for the datasets and stringify it.\n",
    "    import base64\n",
    "    from facets_overview.generic_feature_statistics_generator import GenericFeatureStatisticsGenerator\n",
    "\n",
    "    gfsg = GenericFeatureStatisticsGenerator()\n",
    "    proto = gfsg.ProtoFromDataFrames([{'name': 'train', 'table': train_data},\n",
    "                                  {'name': 'test', 'table': test_data}])\n",
    "    protostr = base64.b64encode(proto.SerializeToString()).decode(\"utf-8\")\n",
    "    \n",
    "    \n",
    "    # Display the facets overview visualization for this data\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "    HTML_TEMPLATE = \"\"\"\n",
    "        <script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\" >\n",
    "        <facets-overview id=\"elem\"></facets-overview>\n",
    "        <script>\n",
    "          document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n",
    "        </script>\"\"\"\n",
    "    html = HTML_TEMPLATE.format(protostr=protostr)\n",
    "    display(HTML(html))\n",
    "    \n",
    "    \n",
    "    # Distingushing those that died from a factor, from those that didn't\n",
    "    fig,ax = plt.subplots(2,3,figsize=(15,8))\n",
    "    ax1,ax2,ax3,ax4, ax5, ax6 = ax.flatten()\n",
    "\n",
    "    sns.countplot(df['anaemia'], hue = df[\"DEATH_EVENT\"],ax=ax1)\n",
    "    sns.countplot(df['diabetes'],hue = df[\"DEATH_EVENT\"],ax=ax2)\n",
    "    sns.countplot(df['high_blood_pressure'],hue = df[\"DEATH_EVENT\"], ax=ax3)\n",
    "    sns.countplot(df['sex'],hue = df[\"DEATH_EVENT\"], ax=ax4)\n",
    "    sns.countplot(df['smoking'],hue = df[\"DEATH_EVENT\"], ax=ax5)\n",
    "    sns.countplot(df['DEATH_EVENT'],hue = df[\"DEATH_EVENT\"], ax=ax6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess(data_path)\n",
    "# def feature_engineer(data_path):\n",
    "    \n",
    "#      # func_to_container_op requires packages to be imported inside of the function.\n",
    "#     import sys, subprocess;\n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22']) \n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy==1.16.1'])\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     import pickle\n",
    "#     from pandas import Series, DataFrame,read_csv\n",
    "    \n",
    "#     # load the preprocessed data\n",
    "#     # preprocess(data_path)\n",
    "#     df = pd.read_pickle(f'{data_path}/preprocessed-data.pkl')\n",
    "    \n",
    "    \n",
    "#     # Re-engineer some features based on generally accepted medical values for those feature\n",
    "    \n",
    "#     # creatinine_phosphokinase normal values ranges from 10 to 120 micrograms per liter (mcg/L) creatinine_phosphokinase\n",
    "#     def set_cpk(row):\n",
    "#         if row[\"creatinine_phosphokinase\"] >= 10 and row[\"creatinine_phosphokinase\"] <= 120:\n",
    "#             return 'Normal'\n",
    "#         else:\n",
    "#             return \"High\"\n",
    "#     df['cp_desc'] =  df.apply(set_cpk, axis=1)\n",
    "#     # line 27\n",
    "    \n",
    "#     # Range of EJECTION FRACTION for Heart Failure\n",
    "#     def set_eject_fract(row):\n",
    "#         if row[\"ejection_fraction\"] <= 35:\n",
    "#             return \"Low\"\n",
    "#         elif row[\"ejection_fraction\"] > 35 and row[\"ejection_fraction\"] <= 49:\n",
    "#             return \"Below_Normal\"\n",
    "#         elif row[\"ejection_fraction\"] > 50 and row[\"ejection_fraction\"] <= 75:\n",
    "#             return \"Normal\"\n",
    "#         else:\n",
    "#             return \"High\"\n",
    "#     df['ejection_fraction_desc'] =  df.apply(set_eject_fract, axis =1)\n",
    "    \n",
    "#     # line 41\n",
    "#     # Range of PLATELETS for Male and Female\n",
    "#     def set_platelets(row):\n",
    "#         if row[\"sex\"] == 'Female':  #females\n",
    "#             if row[\"platelets\"] < 157000:\n",
    "#                 return \"Low\"\n",
    "#             elif row[\"platelets\"] >=157000 and row[\"platelets\"] <= 371000:\n",
    "#                 return \"Normal\"\n",
    "#             else:\n",
    "#                 return \"High\"\n",
    "            \n",
    "#         elif row[\"sex\"] == 'Male':  #males\n",
    "#             if row[\"platelets\"] < 135000:\n",
    "#                 return \"Low\"\n",
    "#             if row[\"platelets\"] >= 135000 and row[\"platelets\"] <= 317000:\n",
    "#                 return \"Normal\"\n",
    "#             else:\n",
    "#                 return \"High\"\n",
    "#     df['platelets_desc'] = df.apply(set_platelets, axis = 1)\n",
    "# #     df['platelets_desc'] = df.apply(set_platelets, axis = 1)\n",
    "    \n",
    "    # 62\n",
    "#     # Range of SERUM SODIUM for Heart Failure\n",
    "#     def set_sodium(row):\n",
    "#         if row[\"serum_sodium\"] < 135:\n",
    "#             return \"Low\"\n",
    "#         elif row[\"serum_sodium\"] >=135 and row[\"serum_sodium\"] <= 145:\n",
    "#             return \"Normal\"\n",
    "#         else:\n",
    "#             return \"High\"\n",
    "#     df['sodium_desc'] = df.apply(set_sodium, axis =1)\n",
    "    \n",
    "    \n",
    "#     # Range of SERUM CREATININE for Heart Failure (Varies for male and female)\n",
    "#     def set_creatinine(row):\n",
    "#         if row['sex'] == 'Female':  # females\n",
    "#             if  row['serum_creatinine'] >= 0.5 and  row['serum_creatinine'] <= 1.1:\n",
    "#                 return 'Normal'\n",
    "#             else:\n",
    "#                 return \"High\"\n",
    "            \n",
    "#         elif row['sex'] == 'Male':\n",
    "#             if  row['serum_creatinine'] >= 0.6 and row['serum_creatinine'] <= 1.2:\n",
    "#                 return 'Normal'\n",
    "#             else:\n",
    "#                 return \"High\"\n",
    "#     df['serum_creatinine_desc'] = df.apply(set_creatinine, axis = 1)\n",
    "    \n",
    "    \n",
    "#     # Save the dataframe\n",
    "#     df.to_pickle(f'{data_path}/feature-engineered.pkl')\n",
    "#     print(\"Feature Engineering Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Transformation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_transform(data_path):\n",
    "    \n",
    "     # func_to_container_op requires packages to be imported inside of the function.\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy==1.16.1'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'imblearn==0.0'])\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.utils import shuffle\n",
    "    import imblearn\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    \n",
    "    # Read the preprocessed pickle data file\n",
    "    df = pd.read_pickle(f'{data_path}/preprocessed-data.pkl')\n",
    "    \n",
    "    # Features and labels\n",
    "    x = df.drop('DEATH_EVENT', axis = 1)\n",
    "    y = df['DEATH_EVENT']\n",
    "    \n",
    "    \n",
    "    # use SMOTENC (Synthetic Minority Over-sampling Technique for Nominal and Continuous (SMOTE-NC)), \n",
    "    # for imbalance between the target class\n",
    "    smote = SMOTENC(random_state=1,categorical_features=[0,1,3,5,9,10])\n",
    "    x_bal, y_bal = smote.fit_sample(x, y)\n",
    "    x_bal = pd.DataFrame(x_bal, columns = x.columns)\n",
    "    \n",
    "    # create dummy variables for the newly engineered features.\n",
    "    encode = ['sex']\n",
    "    x = pd.get_dummies(x_bal, columns = encode, drop_first = True)\n",
    "    \n",
    "    # Columns (Features)\n",
    "    col = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time',\n",
    "       'anaemia','diabetes','high_blood_pressure','smoking','sex_Male']\n",
    "    \n",
    "    # Scale the data\n",
    "    col_trans = ColumnTransformer(remainder='passthrough',\n",
    "                              transformers = [('scaler',MinMaxScaler(),[0,2,4,6,7,8,10])])\n",
    "    trans = col_trans.fit_transform(x)\n",
    "    trans = pd.DataFrame(trans,columns = col)\n",
    "    \n",
    "    #output file to path\n",
    "    np.savez_compressed(f'{data_path}/scale_transform-data.npz', \n",
    "                       x=trans,\n",
    "                       y_bal=y_bal)\n",
    "    print(\"Scale and transform Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tf-nightly-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "# tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import datetime, os\n",
    "\n",
    "# logs_base_dir = \"./logs\"\n",
    "# os.makedirs(logs_base_dir, exist_ok=True)\n",
    "# %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your component returns multiple outputs, annotate your function with the typing.NamedTuple type hint and use the collections.namedtuple function return your function's outputs as a new subclass of tuple.\n",
    "\n",
    "- You can also return metadata and metrics from your function.\n",
    "\n",
    "    - Metadata helps you visualize pipeline results.\n",
    "    - Metrics help you compare pipeline runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def training(data_path, classifier_file) -> NamedTuple(\n",
    "    'TrainingOutput',\n",
    "    [\n",
    "        ('mlpipeline_ui_metadata', 'UI_metadata')\n",
    "#         ('mlpipeline_metrics', 'Metrics')\n",
    "    ]):\n",
    "    \n",
    "    # func_to_container_op requires packages to be imported inside of the function.\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy==1.16.1'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'imblearn==0.0']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'jsonlib==1.6.1']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'tensorflow==2.1.0'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'tensorboard==2.1.0'])  \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'DateTime == 4.1.1'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'IPython==7.12.0'])\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import imblearn\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    #load the transformed data\n",
    "    scale_transformed_data = np.load(f'{data_path}/scale_transform-data.npz')\n",
    "    x = scale_transformed_data['x']\n",
    "    y = scale_transformed_data['y_bal']\n",
    "    \n",
    "    # split data into training and testing set\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    # Instantiate classifier with obtained optimum parameters for training\n",
    "    classifier = RandomForestClassifier(max_features= 'auto',random_state = 3,\n",
    "                                    min_samples_leaf = 1, min_samples_split = 2,n_estimators = 100)\n",
    "    \n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    import json\n",
    "#     import datetime, os\n",
    "    from datetime import datetime\n",
    "#     %load_ext tensorboard \n",
    "    \n",
    "#     logdir = \"/home/jovyan/stage-f-07-heart-failure/pipeline/logs/\" + datetime.now().strftime(\"%d/%m/%Y - %H:%M:%S\")\n",
    "#     tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    \n",
    "    \n",
    "    # Fit to x_train and y_train\n",
    "    classifier.fit(x_train, y_train, )\n",
    "    \n",
    "    \n",
    "    # Export a sample tensorboard\n",
    "    metadata = {\n",
    "      'outputs' : [{\n",
    "        'type': 'tensorboard',\n",
    "        'source': 'gs://ml-pipeline-dataset/tensorboard-train',\n",
    "      }]\n",
    "    }\n",
    "    \n",
    "    with open('/mlpipeline-ui-metadata.json', 'w') as f:\n",
    "      json.dump(metadata, f)\n",
    "          \n",
    "    # output the splitted data file to path\n",
    "    np.savez_compressed(f'{data_path}/train-test-data.npz', \n",
    "                       x_train=x_train,\n",
    "                       x_test=x_test,\n",
    "                       y_train=y_train,\n",
    "                       y_test=y_test)\n",
    "    \n",
    "    # Save the classifier model to the designated \n",
    "    with open(f'{data_path}/{classifier_file}', 'wb') as file:\n",
    "        pickle.dump(classifier, file)\n",
    "        \n",
    "    \n",
    "        \n",
    "    from collections import namedtuple\n",
    "    training_output = namedtuple(\n",
    "        'TrainingOutput',\n",
    "        ['classifier', 'mlpipeline_ui_metadata']) \n",
    "    return training_output(classifier, json.dumps(metadata)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def model_validation(data_path, classifier_file) -> NamedTuple(\n",
    "    'ModelvalidationOutputs',\n",
    "    [\n",
    "      ('recall', float),\n",
    "      ('accuracy', float),\n",
    "      ('precision', float),\n",
    "      ('f1score', float),\n",
    "#       ('mlpipeline_ui_metadata', 'UI_metadata'),\n",
    "      ('mlpipeline_metrics', 'Metrics')\n",
    "    ]):\n",
    "    \n",
    "     # func_to_container_op requires packages to be imported inside of the function.\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy==1.16.1'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'jsonlib==1.6.1']) \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import pickle\n",
    "    from sklearn.metrics import classification_report, recall_score, accuracy_score,precision_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # load the transformed data\n",
    "    train_test_data = np.load(f'{data_path}/train-test-data.npz')\n",
    "    x_train = train_test_data['x_train']\n",
    "    x_test  = train_test_data['x_test']\n",
    "    y_train = train_test_data['y_train']\n",
    "    y_test  = train_test_data['y_test']\n",
    "    \n",
    "    # Load the saved classifier model\n",
    "    with open(f'{data_path}/{classifier_file}', 'rb') as file:\n",
    "        classifier = pickle.load(file)\n",
    "    \n",
    "    # predict on x_test\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    \n",
    "    # Model Evaluation\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    f1score = f1_score(y_test,y_pred)\n",
    "    \n",
    "    # Classification Report table\n",
    "    report = classification_report(y_test,y_pred)\n",
    "    print(report)\n",
    "\n",
    "    # Export metrics\n",
    "    metrics = {\n",
    "      'metrics': [{\n",
    "        'name': 'accuracy-score', # The name of the metric. Visualized as the column name in the runs table.\n",
    "        'numberValue':  accuracy, # The value of the metric. Must be a numeric value.\n",
    "        'format': \"PERCENTAGE\",   # The optional format of the metric. Supported values are \"RAW\" (displayed in raw format) and \"PERCENTAGE\" (displayed in percentage format).\n",
    "      },{\n",
    "        'name': 'recall-score',\n",
    "        'numberValue': recall,\n",
    "        'format': \"PERCENTAGE\",\n",
    "      },{\n",
    "        'name': 'precision-score',\n",
    "        'numberValue': precision,\n",
    "        'format': \"PERCENTAGE\",\n",
    "      },{\n",
    "        'name': 'f1score',\n",
    "        'numberValue': f1score,\n",
    "        'format': \"PERCENTAGE\",\n",
    "      }]}\n",
    "    \n",
    "    \n",
    "    # The Report file\n",
    "    with open(f'{data_path}/result.txt', 'w') as result:\n",
    "        result.write(\"Report: {} \".format(report))\n",
    "    \n",
    "    #output the splitted data file to path\n",
    "    np.savez_compressed(f'{data_path}/validated-data.npz', \n",
    "                       x_test=x_test,\n",
    "                       y_test=y_test,\n",
    "                       y_pred=y_pred)\n",
    "\n",
    "    # Save y_pred and y_test as pickle files\n",
    "    pickle.dump(y_pred, open(f'{data_path}/y_pred.pkl','wb'))\n",
    "    pickle.dump(y_test, open(f'{data_path}/y_test.pkl','wb'))\n",
    "    \n",
    "    # Save the classifier model to the designated \n",
    "    with open(f'{data_path}/{classifier_file}', 'wb') as file:\n",
    "        pickle.dump(classifier, file)\n",
    "        \n",
    "        \n",
    "    with open(f'{data_path}/classifier_result.txt', 'w') as result:\n",
    "        result.write(\" Prediction: {},\\n\\nActual: {} \".format(y_pred, y_test))\n",
    "        \n",
    "    from collections import namedtuple\n",
    "    model_eval_output = namedtuple(\n",
    "        'ModelvalidationOutputs',\n",
    "        ['accuracy', 'recall', 'precision', 'f1score',  'mlpipeline_metrics']) \n",
    "    return model_eval_output(accuracy, recall, precision, f1score,  json.dumps(metrics)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def Confusion_matrix(data_path, classifier_file):\n",
    "    \n",
    "     # func_to_container_op requires packages to be imported inside of the function.\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pip==20.2.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy==1.16.1'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'matplotlib==3.3.1']) \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'jsonlib==1.6.1']) \n",
    "    import json\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    \n",
    "    # Load the saved classifier model\n",
    "    with open(f'{data_path}/{classifier_file}', 'rb') as file:\n",
    "        classifier = pickle.load(file)\n",
    "        \n",
    "    # Load the y_pred data file\n",
    "    pickle_in = open(f'{data_path}/y_pred.pkl',\"rb\")\n",
    "    y_pred = pickle.load(pickle_in)\n",
    "    \n",
    "    # Load the y_test data file\n",
    "    pickle_ = open(f'{data_path}/y_test.pkl',\"rb\")\n",
    "    y_test = pickle.load(pickle_)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    matrix = confusion_matrix(y_test.reshape(-1,1), y_pred)\n",
    "    print(matrix)\n",
    "    \n",
    "#     from collections import namedtuple\n",
    "#     confusion_matrix_output = namedtuple(\n",
    "#         'Confusionmatrix',\n",
    "#         ['mlpipeline_metrics']) \n",
    "#     return confusion_matrix_output(json.dumps(metrics)) \n",
    "\n",
    "\n",
    "#      metadata = {\n",
    "#     'outputs' : [{\n",
    "#       'type': 'confusion_matrix',\n",
    "#       'format': 'csv',\n",
    "#       'schema': [\n",
    "#         {'name': 'target', 'type': 'CATEGORY'},\n",
    "#         {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "#         {'name': 'count', 'type': 'NUMBER'},\n",
    "#       ],\n",
    "#       'source': <CONFUSION_MATRIX_CSV_FILE>,\n",
    "#       # Convert vocab to string because for bealean values we want \"True|False\" to match csv data.\n",
    "#       'labels': list(map(str, vocab)),\n",
    "#     }]\n",
    "#   }\n",
    "#   with file_io.FileIO('/mlpipeline-ui-metadata.json', 'w') as f:\n",
    "#     json.dump(metadata, f)\n",
    "\n",
    "\n",
    "#     with open(f'{data_path}/classifier_result.txt', 'w') as result:\n",
    "#         result.write(\" Prediction: {},\\nActual: {} \".format(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a pipeline component from the function\n",
    "\n",
    "#### Convert the function to a pipeline operation.\n",
    "\n",
    "- Use `kfp.components.create_component_from_func` to return a factory function that you can use to create `kfp.dsl.ContainerOp` class instances for the pipeline. We also specify the base container image to run this function in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproces lightweight components.\n",
    "preprocess_op = comp.func_to_container_op(preprocess, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the analysis lightweight components.\n",
    "analyze_op = comp.func_to_container_op(Analyze, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the feature Engineering lightweight components.\n",
    "# feature_engineer_op = comp.func_to_container_op(feature_engineer, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the scale and transform lightweight components.\n",
    "scale_transform_op = comp.func_to_container_op(scale_transform, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the training lightweight components.\n",
    "training_op = comp.func_to_container_op(training, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the model evaluation lightweight components.\n",
    "model_validation_op = comp.func_to_container_op(model_validation, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create the confusion matrix lightweight components.\n",
    "confusion_matrix_op = comp.func_to_container_op(Confusion_matrix, base_image=BASE_IMAGE)\n",
    "\n",
    "# Create predict_classifier lightweight components.\n",
    "# training_op = comp.func_to_container_op(training, base_image=BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Kubeflow Pipeline\n",
    "\n",
    "- Our next step will be to create the various components that will make up the pipeline. Define the pipeline using the *@dsl.pipeline* decorator.\n",
    "\n",
    "\n",
    "- The pipeline function is defined and includes a number of paramters that will be fed into our various components throughout execution. Kubeflow Pipelines are created decalaratively. This means that the code is not run until the pipeline is compiled.\n",
    "\n",
    "\n",
    "- A [Persistent Volume Claim](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) can be quickly created using the [VolumeOp](https://) method to save and persist data between the components. \n",
    "   - Note that while this is a great method to use locally, you could also use a `cloud bucket` for your persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain-specific language \n",
    "# Define the Pipeline\n",
    "@dsl.pipeline(\n",
    "    name='Heart Failure Prediction Pipeline',\n",
    "    description='End-to-end training machine learning to predict mortality by heart failure.'\n",
    ")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def Heart_Failure_container_pipeline(\n",
    "    data_path: str,  # DATA_PATH\n",
    "    classifier_file: str  # CLASSIFIER_PATH    \n",
    "):\n",
    "    \n",
    "    # Create a persistent volume\n",
    "    # Define volume to share data between components\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"creat_volume\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    # Define Pipeline Components and dependencies\n",
    "    # We do this with ContainerOp, an object that defines a pipeline component from a container.\n",
    "    \n",
    "    # Create Heart Failure preprocessing component.\n",
    "    heart_failure_preprocessing_container = preprocess_op(data_path).add_pvolumes({data_path: vop.volume})\n",
    "    \n",
    "    # Create Heart Failure analysis component\n",
    "    heart_failure_analyze_container = analyze_op(data_path).add_pvolumes({data_path: vop.volume})\n",
    "    \n",
    "    # Create Heart Failure Feature Engineering component\n",
    "#     heart_failure_feature_engineer_container = feature_engineer_op(data_path) \\\n",
    "#                                                 .add_pvolumes({data_path: heart_failure_preprocessing_container.pvolume})\n",
    "    \n",
    "    # Create Heart Failure Scale and transform component\n",
    "    heart_failure_scale_transform_container = scale_transform_op(data_path) \\\n",
    "                                                .add_pvolumes({data_path: heart_failure_preprocessing_container.pvolume})\n",
    "    \n",
    "    # Create Heart Failure training component\n",
    "    heart_failure_training_container = training_op(data_path, classifier_file) \\\n",
    "                                        .add_pvolumes({data_path: heart_failure_scale_transform_container.pvolume})\n",
    "    \n",
    "    # Create Heart Failure model evaluation component\n",
    "    heart_failure_model_validation_container = model_validation_op(data_path, classifier_file) \\\n",
    "                                        .add_pvolumes({data_path: heart_failure_training_container.pvolume})\n",
    "    \n",
    "    # Create Heart Failure confusion matrix component\n",
    "    heart_failure_confusion_matrix_container = confusion_matrix_op(data_path, classifier_file) \\\n",
    "                                        .add_pvolumes({data_path: heart_failure_model_validation_container.pvolume})\n",
    "    \n",
    "    # Create Heart Failure ROC Curve component\n",
    "#     heart_failure_roc_container = roc_op(data_path, classifier_file) \\\n",
    "#                                         .add_pvolumes({data_path: heart_failure_model_validation.pvolume})\n",
    "\n",
    "\n",
    "    \n",
    "     # Print the result of the prediction\n",
    "    Heart_Failure_result_container = dsl.ContainerOp(\n",
    "        name=\"Heart Failure prediction\",  # the name displayed for the component execution during runtime.\n",
    "        image='library/bash:4.4.23',      # Image tag for the Docker container to be used.\n",
    "        pvolumes={data_path: heart_failure_model_validation_container.pvolume}, # dictionary of paths and associated Persistent Volumes to be mounted to the container before execution.\n",
    "        arguments=['cat', f'{data_path}/classifier_result.txt'] # command to be run by the container at runtime.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and run the pipeline\n",
    "\n",
    "- Finally we feed our pipeline definition into the compiler and run it as an experiment. This will give us 2 links at the bottom that we can follow to the [Kubeflow Pipelines UI](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) where you can check logs, artifacts, inputs/outputs, and visually see the progress of your pipeline.\n",
    "\n",
    "\n",
    "- Kubeflow Pipelines lets you group pipeline runs by Experiments. You can create a new experiment, or call `kfp.Client().list_experiments()` to see existing ones. If you don't specify the experiment name, the Default experiment will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some environment variables which are to be used as inputs at various points in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt'  # mount your filesystems or devices\n",
    "CLASSIFIER_PATH = 'heart_main.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = Heart_Failure_container_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/kfp/dsl/_container_op.py:1028: FutureWarning: Please create reusable components instead of constructing ContainerOp instances directly. Reusable components are shareable, portable and have compatibility and support guarantees. Please see the documentation: https://www.kubeflow.org/docs/pipelines/sdk/component-development/#writing-your-component-definition-file The components can be created manually (or, in case of python, using kfp.components.create_component_from_func or func_to_container_op) and then loaded using kfp.components.load_component_from_file, load_component_from_uri or load_component_from_text: https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.load_component_from_file\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/b9903817-ff24-4b2b-a0ff-75ee349257e1\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/dc943efe-3677-42ea-bca1-dcff28664d94\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_name=EXPERIMENT_NAME\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH,\n",
    "             \"classifier_file\":CLASSIFIER_PATH}\n",
    "\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,'{}.zip'.format(experiment_name))\n",
    "\n",
    "\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
